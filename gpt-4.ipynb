{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial\n",
    "import pretty_errors\n",
    "import timeit\n",
    "import logging\n",
    "import time\n",
    "import asyncio\n",
    "from openai.error import OpenAIError\n",
    "import json\n",
    "from typing import Callable\n",
    "from utils.preprocess import individual_preprocess\n",
    "from dotenv import load_dotenv\n",
    "from utils.SummariseJob import summarise_job_gpt\n",
    "from utils.AsyncSummariseJob import async_summarise_description\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from utils.handy import e5_base_v2_query, LoggingGPT4, filter_last_two_weeks\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "host = os.getenv(\"host\")\n",
    "port = os.getenv(\"port\")\n",
    "database = os.getenv(\"database\")\n",
    "SAVE_PATH = os.getenv(\"SAVE_PATH\")\n",
    "E5_BASE_V2_DATA = os.getenv(\"E5_BASE_V2_DATA\")\n",
    "\n",
    "\n",
    "#Start the timer\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "#GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_MODEL = \"gpt-4\"\n",
    "#GPT_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "\"\"\"\"\n",
    "Load the embedded file\n",
    "\"\"\"\n",
    "\n",
    "logging.basicConfig(filename='/Users/juanreyesgarcia/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/logs/LoggingGPT4.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "embeddings_path = E5_BASE_V2_DATA\n",
    "\n",
    "df_unfiltered = pd.read_parquet(embeddings_path)\n",
    "\n",
    "df = filter_last_two_weeks(df_unfiltered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_ranked_by_relatedness_e5(query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    #Modify this to get more jobs\n",
    "    top_n: int = 10\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \n",
    "    #the query is embedded using e5\n",
    "    query_embedding = e5_base_v2_query(query=query)\n",
    "\n",
    "    ids_and_relatednesses = [\n",
    "        (row[\"id\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    ids_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    ids, relatednesses = zip(*ids_and_relatednesses)\n",
    "    return ids[:top_n], relatednesses[:top_n]     \n",
    "    #Returns a list of strings and relatednesses, sorted from most related to least.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiktoken function -> to count tokens\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delimiters = \"####\"\n",
    "\n",
    "system_prompt=f\"\"\"\n",
    "\n",
    "You are a job recruiter for a large recruitment agency./\n",
    "You will be provided with a candidate's CV./\n",
    "The CV will be delimited with {delimiters} characters./\n",
    "You will also be provided with the Job IDs (delimited by angle brackets) /\n",
    "and corresponding descriptions (delimited by triple dashes)/\n",
    "for the available job openings./\n",
    "\n",
    "Perform the following steps:/\n",
    "\n",
    "Step 1 - Classify the provided CV into a suitability category for each job opening./\n",
    "Step 2 - For each ID briefly explain in one sentence your reasoning behind the chosen suitability category./\n",
    "Step 3 - Only provide your output in json format with the keys: id, suitability and explanation./\n",
    "\n",
    "Do not classify a CV into a suitability category until you have classify the CV yourself.\n",
    "\n",
    "Suitability categories: Highly Suitable, Moderately Suitable, Potentially Suitable, Marginally Suitable and Not Suitable./\n",
    "\n",
    "Highly Suitable: CVs in this category closely align with the job opening, demonstrating extensive relevant experience, skills, and qualifications. The candidate possesses all or most of the necessary requirements and is an excellent fit for the role./\n",
    "Moderately Suitable: CVs falling into this category show a reasonable match to the job opening. The candidate possesses some relevant experience, skills, and qualifications that align with the role, but there may be minor gaps or areas for improvement. With some additional training or development, they could become an effective candidate./\n",
    "Potentially Suitable: CVs in this category exhibit potential and may possess transferable skills or experience that could be valuable for the job opening. Although they may not meet all the specific requirements, their overall profile suggests that they could excel with the right support and training./\n",
    "Marginally Suitable: CVs falling into this category show limited alignment with the job opening. The candidate possesses a few relevant skills or experience, but there are significant gaps or deficiencies in their qualifications. They may require substantial training or experience to meet the requirements of the role./\n",
    "Not Suitable: CVs in this category do not match the requirements and qualifications of the job opening. The candidate lacks the necessary skills, experience, or qualifications, making them unsuitable for the role./\n",
    "\"\"\"\n",
    "\n",
    "introduction_prompt = \"\"\"\n",
    "\n",
    "\n",
    "\\n Available job openings:\\n\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "abstract_cv_past = \"\"\"Data Analyst: Cleansed, analyzed, and visualized data using Python, SQL Server, and Power BI.\n",
    "Legal Assistant: Drafted legal documents, collaborated on negotiation outlines, and handled trademark registrations.\n",
    "Data Analyst Jr.: Implemented A/B testing, utilized data analysis tools, and developed real-time visualizations.\n",
    "Special Needs Counselor: Led and assisted individuals with disabilities, provided personal care, and facilitated camp activities.\n",
    "Total years of professional experience: 3 years.\"\"\"\n",
    "\n",
    "abstract_cv = \"\"\"('Qualifications: \\n- LLB Law degree from Universidad de las Américas Puebla (UDLAP) with an accumulated average of 9.4/10.\\n- Currently on an international exchange at the University of Bristol for the final year of studying Law.\\n- Member of the Honours Program at UDLAP, conducting research on FinTech, Financial Inclusion, Blockchain, Cryptocurrencies, and Smart Contracts.\\n\\nPrevious job titles:\\n- Data Analyst at Tata Consultancy Services México, where I cleansed, interpreted, and analyzed data using Python and SQL Server to produce visual reports with Power BI.\\n- Legal Assistant at BLACKSHIIP Venture Capital, responsible for proofreading and drafting legal documents, as well as assisting with negotiations of International Share Purchase Agreements.\\n\\nResponsibilities/Key Duties:\\n- Developed and introduced A/B testing to make data-driven business decisions as a Data Analyst Jr. at AMATL GRÁFICOS.\\n- Taught mental arithmetic as a Mathematics Instructor at ALOHA Mental Arithmetic.\\n- Led and assisted individuals with physical and mental disabilities as a Special Needs Counsellor at Camp Merrywood and YMCA Camp Independence.\\n\\nSkills:\\n- Proficient in Python, SQL Server, Tableau, Power BI, Bash/Command Line, Git & GitHub, and Office 365.\\n- Strong written and verbal communication skills, teamwork, ability to work under pressure, attention to detail, and leadership skills.\\n- Knowledge in machine learning, probabilities & statistics, and proofreading.\\n\\nOther Achievements:\\n- Published paper on \"Smart Legal Contracts: From Theory to Reality\" and participated in the IDEAS Summer Program on Intelligence, Data, Ethics, and Society at the University of California, San Diego.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_query_summary(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    #Return a message for GPT, with relevant source texts pulled from a dataframe.\n",
    "    ids, relatednesses = ids_ranked_by_relatedness_e5(query, df)\n",
    "    #Basically giving the most relevant IDs from the previous function\n",
    "    introduction = introduction_prompt\n",
    "    query_user = f\"{query}\"\n",
    "    message = introduction\n",
    "    # Create a list of tasks\n",
    "    tasks = [async_summarise_description(df[df['id'] == id]['original'].values[0]) for id in ids]\n",
    "\n",
    "    # Run the tasks concurrently\n",
    "    results = await asyncio.gather(*tasks)    \n",
    "\n",
    "    for id, result in zip(ids, results):\n",
    "        job_description_summary, cost, elapsed_time = result\n",
    "        logging.info(f\"TOTAL COST: {cost}. TOTAL ELAPSED TIME: {elapsed_time}\")\n",
    "        next_id = f'\\nID:<{id}>\\nJob Description:---{job_description_summary}---\\n'\n",
    "        if (\n",
    "            num_tokens(message + next_id + query_user, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_id\n",
    "    return query_user, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "async def ask(\n",
    "    #This query is your question, only parameter to fill in function\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 8192,\n",
    "    log_gpt_messages: bool = True\n",
    ") -> str:\n",
    "    #Answers a query using GPT and a dataframe of relevant texts and embeddings.\n",
    "    query_user, job_id_description = await async_query_summary(query, df, model=model, token_budget=token_budget)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiters}{query_user}{delimiters}\"},\n",
    "        {\"role\": \"assistant\", \"content\": job_id_description}\n",
    "    ]\n",
    "    if log_gpt_messages:\n",
    "        logging.info(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    #if print_cost_and_relatednesses:\n",
    "    total_tokens = response['usage']['total_tokens']\n",
    "    prompt_tokens = response['usage']['prompt_tokens']\n",
    "    completion_tokens = response['usage']['completion_tokens']\n",
    "    logging.info(f\"\\nPROMPT TOKENS USED:{prompt_tokens}\\n COMPLETION TOKENS USED:{completion_tokens}\\n \\nTOTAL TOKENS USED:{total_tokens}\\n\")\n",
    "    #Approximate cost\n",
    "    if GPT_MODEL == \"gpt-4\":\n",
    "        prompt_cost = round((prompt_tokens / 1000) * 0.03, 3)\n",
    "        completion_cost = round((completion_tokens / 1000) * 0.06, 3)\n",
    "        cost_classify = prompt_cost + completion_cost\n",
    "        logging.info(f\"MODEL USED: {GPT_MODEL}. COST FOR CLASSIFYING: ${cost_classify} USD\")\n",
    "    elif GPT_MODEL == \"gpt-3.5-turbo\":\n",
    "        prompt_cost = round((prompt_tokens / 1000) * 0.0015, 3)\n",
    "        completion_cost = round((completion_tokens / 1000) * 0.002, 3)\n",
    "        cost_classify = prompt_cost + completion_cost\n",
    "        logging.info(f\"MODEL USED: {GPT_MODEL}. COST FOR CLASSIFYING: ${cost_classify} USD\")\n",
    "    elif GPT_MODEL == \"gpt-3.5-turbo-16k\":\n",
    "        prompt_cost = round((prompt_tokens / 1000) * 0.003, 3)\n",
    "        completion_cost = round((completion_tokens / 1000) * 0.004, 3)\n",
    "        cost_classify = prompt_cost + completion_cost\n",
    "        logging.info(f\"MODEL USED: {GPT_MODEL}. COST FOR CLASSIFYING: ${cost_classify} USD\")\n",
    "\n",
    "    #relatednesses\n",
    "    ids, relatednesses = ids_ranked_by_relatedness_e5(query=query, df=df)\n",
    "    for id, relatedness in zip(ids, relatednesses):\n",
    "        logging.info(f\"ID: {id} has the following {relatedness=:.3f}\")\n",
    "    \n",
    "    elapsed_time = timeit.default_timer() - start_time\n",
    "    logging.info(f\"\\n DreamedJobAI finished! all in: {elapsed_time:.2f} seconds \\n\")\n",
    "    \n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/_059946j4lvcjpvshx_dj5f40000gn/T/ipykernel_31620/3087904867.py:22: RuntimeWarning: coroutine 'ask.<locals>.calling_async_query_summary' was never awaited\n",
      "  pass\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/juanreyesgarcia/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pygments/regexopt.py:78: RuntimeWarning: coroutine 'ask' was never awaited\n",
      "  for group in groupby(strings, lambda s: s[0] == first[0])) \\\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m, in \u001b[0;36mcheck_output_GPT4\u001b[0;34m(function_gpt4, input_cv)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     python_string \u001b[39m=\u001b[39m function_gpt4(input_cv)\n\u001b[1;32m      9\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[39], line 16\u001b[0m, in \u001b[0;36mask\u001b[0;34m(query, df, model, token_budget, log_gpt_messages)\u001b[0m\n\u001b[1;32m     15\u001b[0m loop \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_running_loop()\n\u001b[0;32m---> 16\u001b[0m query_user, job_id_description \u001b[39m=\u001b[39m loop\u001b[39m.\u001b[39;49mrun_until_complete(calling_async_query_summary())\n\u001b[1;32m     18\u001b[0m messages \u001b[39m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: system_prompt},\n\u001b[1;32m     20\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdelimiters\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mquery_user\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mdelimiters\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     21\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: job_id_description}\n\u001b[1;32m     22\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py:622\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 622\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    624\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py:582\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 582\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    583\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m default_json\n\u001b[1;32m     27\u001b[0m \u001b[39m#checked_json = check_output_GPT4(ask, abstract_cv)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m checked_json \u001b[39m=\u001b[39m check_output_GPT4(ask, abstract_cv)\n\u001b[1;32m     29\u001b[0m \u001b[39m#exp = check_output_GPT4(get_data, 0)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype of the json object: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(checked_json)\u001b[39m}\u001b[39;00m\u001b[39m Data: \u001b[39m\u001b[39m{\u001b[39;00mchecked_json\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 21\u001b[0m, in \u001b[0;36mcheck_output_GPT4\u001b[0;34m(function_gpt4, input_cv)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. Retrying in 5 seconds. Number of retries: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     24\u001b[0m logging\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mCheck logs!!!! Main function was not callable. Setting json to default\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "async def check_output_GPT4(input_cv: str) -> str:\n",
    "    default = '[{\"id\": \"\", \"suitability\": \"\", \"explanation\": \"\"}]'\n",
    "    default_json = json.loads(default)\n",
    "    \n",
    "    for _ in range(6):\n",
    "        i = _ + 1\n",
    "        try:\n",
    "            python_string = await ask(input_cv)\n",
    "            try:\n",
    "                data = json.loads(python_string)\n",
    "                logging.info(f\"Response is a valid json object. Done in loop number: {i}\")\n",
    "                return data\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        except OpenAIError as e:\n",
    "            logging.warning(f\"{e}. Retrying in 10 seconds. Number of retries: {i}\")\n",
    "            time.sleep(10)\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{e}. Retrying in 5 seconds. Number of retries: {i}\")\n",
    "            time.sleep(5)\n",
    "            pass\n",
    "\n",
    "    logging.error(\"Check logs!!!! Main function was not callable. Setting json to default\")\n",
    "    return default_json\n",
    "\n",
    "#checked_json = check_output_GPT4(ask, abstract_cv)\n",
    "checked_json = await check_output_GPT4(abstract_cv)\n",
    "#exp = check_output_GPT4(get_data, 0)\n",
    "\n",
    "logging.info(f\"type of the json object: {type(checked_json)} Data: {checked_json}\")\n",
    "#print(type(exp), exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ids_json_loads(data: list[dict[str, str, str]] = None) -> str:\n",
    "    if data is None:\n",
    "        data = await checked_json\n",
    "    \n",
    "    ids = \"\"\n",
    "    for item in data:\n",
    "        if \"id\" in item:\n",
    "            if ids:\n",
    "                ids += \", \"\n",
    "            ids += f\"'{item['id']}'\"\n",
    "\n",
    "    return f\"({ids})\"\n",
    "\n",
    "ids_ready = await ids_json_loads()\n",
    "logging.info(f\"Getting the ids from the json object: {type(ids_ready)}, {ids_ready}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframe_display_options():\n",
    "    pd.set_option('display.max_columns', None)  # Show all columns\n",
    "    pd.set_option('display.max_rows', None)  # Show all rows\n",
    "    pd.set_option('display.width', None)  # Disable column width restriction\n",
    "    pd.set_option('display.expand_frame_repr', False)  # Disable wrapping to multiple lines\n",
    "    pd.set_option('display.max_colwidth', None)  # Display full contents of each column\n",
    "\n",
    "# Call the function to set the desired display options\n",
    "set_dataframe_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, title, link, location]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def join_postgre_data_with_ids(ids:str) -> pd.DataFrame:\n",
    "    conn = psycopg2.connect(user=user, password=password, host=host, port=port, database=database)\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    cur.execute( f\"SELECT id, title, link, location FROM test WHERE id IN {ids}\")\n",
    "\n",
    "    # Fetch all rows from the table\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Separate the columns into individual lists\n",
    "    all_ids = [row[0] for row in rows]\n",
    "    all_titles = [row[1] for row in rows]\n",
    "    all_links = [row[2] for row in rows]\n",
    "    all_locations = [row[3] for row in rows]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id': all_ids,\n",
    "        'title': all_titles,\n",
    "        'link': all_links,\n",
    "        'location': all_locations\n",
    "    })\n",
    "\n",
    "\n",
    "    # Close the database connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = join_postgre_data_with_ids(ids=ids_ready)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, title, link, location]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def adding_all_data(df: pd.DataFrame, suitable_jobs: list) -> pd.DataFrame:\n",
    "    for index, row in df.iterrows():\n",
    "        entry_id = row['id']\n",
    "        for json_item in suitable_jobs:\n",
    "            if int(json_item['id']) == entry_id:\n",
    "                suitability = json_item['suitability']\n",
    "                explanation = json_item['explanation']\n",
    "                df.at[index, 'suitability'] = suitability\n",
    "                df.at[index, 'explanation'] = explanation\n",
    "                break\n",
    "    return df\n",
    "\n",
    "updated_data = adding_all_data(df=df, suitable_jobs=checked_json)\n",
    "\n",
    "print(updated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ast.py:50: RuntimeWarning: coroutine 'check_output_GPT4' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'suitability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'suitability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     sorted_df \u001b[39m=\u001b[39m sorted_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msuitability_rank\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m sorted_df\n\u001b[0;32m---> 14\u001b[0m sorted_df \u001b[39m=\u001b[39m sort_df_by_suitability()\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(sorted_df)\n\u001b[1;32m     18\u001b[0m test_output\u001b[39m=\u001b[39m sorted_df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m/Users/juanreyesgarcia/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/data/test_output.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36msort_df_by_suitability\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msort_df_by_suitability\u001b[39m(df: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m df) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m      2\u001b[0m     custom_order \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHighly Suitable\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mModerately Suitable\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mNot Suitable\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m5\u001b[39m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[0;32m----> 9\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39msuitability_rank\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39msuitability\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmap(custom_order)\n\u001b[1;32m     10\u001b[0m     sorted_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msuitability_rank\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     sorted_df \u001b[39m=\u001b[39m sorted_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msuitability_rank\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'suitability'"
     ]
    }
   ],
   "source": [
    "def sort_df_by_suitability(df: pd.DataFrame = df) -> pd.DataFrame:\n",
    "    custom_order = {\n",
    "        'Highly Suitable': 1,\n",
    "        'Moderately Suitable': 2,\n",
    "        'Potentially Suitable': 3,\n",
    "        'Marginally Suitable': 4,\n",
    "        'Not Suitable': 5\n",
    "    }\n",
    "    df['suitability_rank'] = df['suitability'].map(custom_order)\n",
    "    sorted_df = df.sort_values(by='suitability_rank')\n",
    "    sorted_df = sorted_df.drop(columns='suitability_rank')\n",
    "    return sorted_df\n",
    "\n",
    "sorted_df = sort_df_by_suitability()\n",
    "\n",
    "print(sorted_df)\n",
    "\n",
    "test_output= sorted_df.to_csv(\"/Users/juanreyesgarcia/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/data/test_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_3_summary = \"\"\"Write an abstract description of the following CV in four bullet points. \n",
    "\n",
    "Let's think step by step to summarise it into four bullet points:\n",
    "\n",
    "1. Focus on the main skills and responsibilities of each role. \n",
    "2. One of the bullet points is the total years of experience.\n",
    "2. Omit the employer names. \n",
    "3. Your answer must be in an active voice. \n",
    "4. Double-check that the summary is in four bullet points, three summarising the main skills and responsibilities and the last one is about the years of experience. \n",
    "CV IS BELOW: \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
