{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial\n",
    "import pretty_errors\n",
    "import timeit\n",
    "from preprocess import individual_preprocess\n",
    "from dotenv import load_dotenv\n",
    "from utils.SummariseJob import summarise_job\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "SAVE_PATH = os.getenv(\"SAVE_PATH\")\n",
    "E5_BASE_TOTAL_JOBS = os.getenv(\"E5_BASE_TOTAL_JOBS\")\n",
    "OPENAI_TOTAL_JOBS = os.getenv(\"OPENAI_TOTAL_JOBS\")\n",
    "\n",
    "#Start the timer\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "#GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_MODEL = \"gpt-4\"\n",
    "#GPT_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "\"\"\"\"\n",
    "Load the embedded file\n",
    "\"\"\"\n",
    "\n",
    "embeddings_path = E5_BASE_TOTAL_JOBS\n",
    "\n",
    "df = pd.read_parquet(embeddings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor,\n",
    "                attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_ranked_by_relatedness_e5(query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    #Modify this to get more jobs\n",
    "    top_n: int = 10\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n",
    "    model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n",
    "\n",
    "    query_preprocess = individual_preprocess(query)\n",
    "    \n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(query_preprocess, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    outputs = model(**batch_dict)\n",
    "    query_embedding = average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).detach().numpy().flatten()\n",
    "    ids_and_relatednesses = [\n",
    "        (row[\"ids\"], relatedness_fn(query_embedding, row[\"embeddings\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    ids_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    ids, relatednesses = zip(*ids_and_relatednesses)\n",
    "    return ids[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiktoken function -> to count tokens\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delimiters = \"####\"\n",
    "\n",
    "system_prompt=f\"\"\"\n",
    "\n",
    "You are a job recruiter for a large recruitment agency./\n",
    "You will be provided with a candidate's CV./\n",
    "The CV will be delimited with {delimiters} characters./\n",
    "You will also be provided with the Job IDs (delimited by angle brackets) /\n",
    "and corresponding descriptions (delimited by triple dashes)/\n",
    "for the available job openings./\n",
    "\n",
    "Perform the following steps:/\n",
    "\n",
    "STEP 1 - {delimiters} Classify the provided CV into a suitability category for each job opening: /\n",
    "- Review the CV thoroughly and assess its suitability for each job opening based on the qualifications, skills, and experience required. /\n",
    "- Consider the match between the CV and the job requirements to determine the suitability category. /\n",
    "\n",
    "STEP 2 - {delimiters} For each ID, briefly explain in one sentence your reasoning behind the chosen suitability category: /\n",
    "- Provide a concise explanation for each ID, highlighting the key factors from the CV that influenced the suitability category assigned. /\n",
    "- Include relevant qualifications, skills, experience, or any other pertinent information that supports the categorization. /\n",
    "\n",
    "STEP 3 - {delimiters} Provide your output in JSON format with the keys: id, suitability, and explanation: /\n",
    "- Organize the output in a JSON format, where each entry includes the ID, suitability category, and the corresponding explanation. /\n",
    "- Use the \"id\" key to store the ID, the \"suitability\" key to store the suitability category, and the \"explanation\" key to store the reasoning explanation. /\n",
    "\n",
    "Remember, do not classify a CV into a suitability category until you have carefully reviewed and assessed its suitability for each job opening. /\n",
    "\n",
    "Suitability categories: Highly Suitable, Moderately Suitable,/\n",
    "Potentially Suitable, Marginally Suitable and Not Suitable./\n",
    "\n",
    "Highly Suitable: CVs in this category closely align with the job opening, demonstrating extensive relevant experience, skills, and qualifications. The candidate possesses all or most of the necessary requirements and is an excellent fit for the role./\n",
    "Moderately Suitable: CVs falling into this category show a reasonable match to the job opening. The candidate possesses some relevant experience, skills, and qualifications that align with the role, but there may be minor gaps or areas for improvement. With some additional training or development, they could become an effective candidate./\n",
    "Potentially Suitable: CVs in this category exhibit potential and may possess transferable skills or experience that could be valuable for the job opening. Although they may not meet all the specific requirements, their overall profile suggests that they could excel with the right support and training./\n",
    "Marginally Suitable: CVs falling into this category show limited alignment with the job opening. The candidate possesses a few relevant skills or experience, but there are significant gaps or deficiencies in their qualifications. They may require substantial training or experience to meet the requirements of the role./\n",
    "Not Suitable: CVs in this category do not match the requirements and qualifications of the job opening. The candidate lacks the necessary skills, experience, or qualifications, making them unsuitable for the role./\n",
    "\"\"\"\n",
    "\n",
    "introduction_prompt = \"\"\"\n",
    "\n",
    "\n",
    "\\n Available job openings:\\n\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "abstract_cv = \"\"\"Data Analyst: Cleansed, analyzed, and visualized data using Python, SQL Server, and Power BI.\n",
    "Legal Assistant: Drafted legal documents, collaborated on negotiation outlines, and handled trademark registrations.\n",
    "Data Analyst Jr.: Implemented A/B testing, utilized data analysis tools, and developed real-time visualizations.\n",
    "Special Needs Counselor: Led and assisted individuals with disabilities, provided personal care, and facilitated camp activities.\n",
    "Total years of professional experience: 3 years.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    #Return a message for GPT, with relevant source texts pulled from a dataframe\n",
    "    ids, relatednesses = ids_ranked_by_relatedness_e5(query, df)\n",
    "    #Basically giving the most relevant IDs from the previous function\n",
    "    introduction = introduction_prompt\n",
    "    query_user = f\"{query}\"\n",
    "    message = introduction\n",
    "    total_cost_summarise_job = 0\n",
    "    for id in ids:\n",
    "        #Get the text for GPT to answer the question\n",
    "        job_description = df[df['ids'] == id]['text_data'].values[0] \n",
    "        \n",
    "        #Summarise the job description with GPT-3.5\n",
    "        job_summarised, cost = summarise_job(job_description)\n",
    "        total_cost_summarise_job += cost\n",
    "        # Add job descriptions to the message along with job ID\n",
    "        next_id = f'\\nID:<{id}>\\nJob Description:---{job_summarised}---\\n'\n",
    "        if (\n",
    "            num_tokens(message + next_id + query_user, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_id\n",
    "    return query_user, message, total_cost_summarise_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def query_message(\\n    query: str,\\n    df: pd.DataFrame,\\n    model: str,\\n    token_budget: int\\n) -> str:\\n    #Return a message for GPT, with relevant source texts pulled from a dataframe.\\n    ids, relatednesses = ids_ranked_by_relatedness_e5(query, df)\\n    #Basically giving the most relevant IDs from the previous function\\n    introduction = introduction_prompt\\n    query_user = f\"{query}\"\\n    message = introduction\\n    #total_cost_summarise_job = 0\\n    for id in ids:\\n        #Get the text for GPT to answer the question\\n        job_description = df[df[\\'ids\\'] == id][\\'text_data\\'].values[0] \\n        \\n        #Summarise the job description with GPT-3.5\\n        #job_summarised, cost = summarise_job(job_description)\\n        #total_cost_summarise_job += cost\\n        # Add job descriptions to the message along with job ID\\n        next_id = f\\'\\nID:<{id}>\\nJob Description:---{job_description}---\\n\\'\\n        if (\\n            num_tokens(message + next_id + query_user, model=model)\\n            > token_budget\\n        ):\\n            break\\n        else:\\n            message += next_id\\n    return query_user, message'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    #Return a message for GPT, with relevant source texts pulled from a dataframe.\n",
    "    ids, relatednesses = ids_ranked_by_relatedness_e5(query, df)\n",
    "    #Basically giving the most relevant IDs from the previous function\n",
    "    introduction = introduction_prompt\n",
    "    query_user = f\"{query}\"\n",
    "    message = introduction\n",
    "    #total_cost_summarise_job = 0\n",
    "    for id in ids:\n",
    "        #Get the text for GPT to answer the question\n",
    "        job_description = df[df['ids'] == id]['text_data'].values[0] \n",
    "        \n",
    "        #Summarise the job description with GPT-3.5\n",
    "        #job_summarised, cost = summarise_job(job_description)\n",
    "        #total_cost_summarise_job += cost\n",
    "        # Add job descriptions to the message along with job ID\n",
    "        next_id = f'\\nID:<{id}>\\nJob Description:---{job_description}---\\n'\n",
    "        if (\n",
    "            num_tokens(message + next_id + query_user, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_id\n",
    "    return query_user, message\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    #This query is your question, only parameter to fill in function\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096,\n",
    "    print_gpt_messages: bool = True,\n",
    "    print_cost_and_relatednesses: bool = True\n",
    ") -> str:\n",
    "    #Answers a query using GPT and a dataframe of relevant texts and embeddings.\n",
    "    query_user, job_id_description, total_cost_summarise_job = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiters}{query_user}{delimiters}\"},\n",
    "        {\"role\": \"assistant\", \"content\": job_id_description}\n",
    "    ]\n",
    "    if print_gpt_messages:\n",
    "        print(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    if print_cost_and_relatednesses:\n",
    "        total_tokens = response['usage']['total_tokens']\n",
    "        prompt_tokens = response['usage']['prompt_tokens']\n",
    "        completion_tokens = response['usage']['completion_tokens']\n",
    "        print(f\"\\nPROMPT TOKENS USED:{prompt_tokens}\\n\", f\"COMPLETION TOKENS USED:{completion_tokens}\\n\", f\"\\nTOTAL TOKENS USED:{total_tokens}\\n\", )\n",
    "        #Approximate cost\n",
    "        if GPT_MODEL == \"gpt-4\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.03, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.06, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            final_cost = total_cost_summarise_job + cost_classify\n",
    "            print(f\"FINAL COST: ${final_cost} USD\")\n",
    "        elif GPT_MODEL == \"gpt-3.5-turbo\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.0015, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.002, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            final_cost = total_cost_summarise_job + cost_classify\n",
    "            print(f\"FINAL COST: ${final_cost} USD\")\n",
    "        elif GPT_MODEL == \"gpt-3.5-turbo-16k\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.003, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.004, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            final_cost = total_cost_summarise_job + cost_classify\n",
    "            print(f\"FINAL COST: ${final_cost} USD\")\n",
    "\n",
    "        #relatednesses\n",
    "        ids, relatednesses = ids_ranked_by_relatedness_e5(query=query, df=df)\n",
    "        print(f\"\\nTHE IDs ARE RANKED BY RELEVANCE:\\n\")\n",
    "        for id, relatedness in zip(ids, relatednesses):\n",
    "            print(f\"ID: {id} has the following {relatedness=:.3f}\")\n",
    "\n",
    "        elapsed_time = timeit.default_timer() - start_time\n",
    "        print(\"\\n\", f\"DreamedJobAI finished! all in: {elapsed_time:.2f} seconds\", \"\\n\") \n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def ask(\\n    #This query is your question, only parameter to fill in function\\n    query: str,\\n    df: pd.DataFrame = df,\\n    model: str = GPT_MODEL,\\n    token_budget: int = 8192,\\n    print_gpt_messages: bool = True,\\n    print_cost_and_relatednesses: bool = True\\n) -> str:\\n    #Answers a query using GPT and a dataframe of relevant texts and embeddings.\\n    query_user, job_id_description = query_message(query, df, model=model, token_budget=token_budget)\\n    messages = [\\n        {\"role\": \"system\", \"content\": system_prompt},\\n        {\"role\": \"user\", \"content\": f\"{delimiters}{query_user}{delimiters}\"},\\n        {\"role\": \"assistant\", \"content\": job_id_description},\\n        {\"role\": \"user\", \"content\": user_reminder}\\n    ]\\n    if print_gpt_messages:\\n        print(messages)\\n    response = openai.ChatCompletion.create(\\n        model=model,\\n        messages=messages,\\n        temperature=0\\n    )\\n    response_message = response[\"choices\"][0][\"message\"][\"content\"]\\n    \\n    if print_cost_and_relatednesses:\\n        total_tokens = response[\\'usage\\'][\\'total_tokens\\']\\n        prompt_tokens = response[\\'usage\\'][\\'prompt_tokens\\']\\n        completion_tokens = response[\\'usage\\'][\\'completion_tokens\\']\\n        print(f\"\\nPROMPT TOKENS USED:{prompt_tokens}\\n\", f\"COMPLETION TOKENS USED:{completion_tokens}\\n\", f\"\\nTOTAL TOKENS USED:{total_tokens}\\n\", )\\n        #Approximate cost\\n        if GPT_MODEL == \"gpt-4\":\\n            prompt_cost = round((prompt_tokens / 1000) * 0.03, 3)\\n            completion_cost = round((completion_tokens / 1000) * 0.06, 3)\\n            cost_classify = prompt_cost + completion_cost\\n            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\\n            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\\n            #final_cost = total_cost_summarise_job + cost_classify\\n            #print(f\"FINAL COST: ${final_cost} USD\")\\n        elif GPT_MODEL == \"gpt-3.5-turbo\":\\n            prompt_cost = round((prompt_tokens / 1000) * 0.0015, 3)\\n            completion_cost = round((completion_tokens / 1000) * 0.002, 3)\\n            cost_classify = prompt_cost + completion_cost\\n            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\\n            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\\n            #final_cost = total_cost_summarise_job + cost_classify\\n            #print(f\"FINAL COST: ${final_cost} USD\")\\n        elif GPT_MODEL == \"gpt-3.5-turbo-16k\":\\n            prompt_cost = round((prompt_tokens / 1000) * 0.003, 3)\\n            completion_cost = round((completion_tokens / 1000) * 0.004, 3)\\n            cost_classify = prompt_cost + completion_cost\\n            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\\n            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\\n            #final_cost = total_cost_summarise_job + cost_classify\\n            #print(f\"FINAL COST: ${final_cost} USD\")\\n\\n        #relatednesses\\n        ids, relatednesses = ids_ranked_by_relatedness_e5(query=query, df=df)\\n        print(f\"\\nTHE IDs ARE RANKED BY RELEVANCE:\\n\")\\n        for id, relatedness in zip(ids, relatednesses):\\n            print(f\"ID: {id} has the following {relatedness=:.3f}\")\\n        \\n        elapsed_time = timeit.default_timer() - start_time\\n        print(\"\\n\", f\"DreamedJobAI finished! all in: {elapsed_time:.2f} seconds\", \"\\n\") \\n    return response_message'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def ask(\n",
    "    #This query is your question, only parameter to fill in function\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 8192,\n",
    "    print_gpt_messages: bool = True,\n",
    "    print_cost_and_relatednesses: bool = True\n",
    ") -> str:\n",
    "    #Answers a query using GPT and a dataframe of relevant texts and embeddings.\n",
    "    query_user, job_id_description = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiters}{query_user}{delimiters}\"},\n",
    "        {\"role\": \"assistant\", \"content\": job_id_description},\n",
    "        {\"role\": \"user\", \"content\": user_reminder}\n",
    "    ]\n",
    "    if print_gpt_messages:\n",
    "        print(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    if print_cost_and_relatednesses:\n",
    "        total_tokens = response['usage']['total_tokens']\n",
    "        prompt_tokens = response['usage']['prompt_tokens']\n",
    "        completion_tokens = response['usage']['completion_tokens']\n",
    "        print(f\"\\nPROMPT TOKENS USED:{prompt_tokens}\\n\", f\"COMPLETION TOKENS USED:{completion_tokens}\\n\", f\"\\nTOTAL TOKENS USED:{total_tokens}\\n\", )\n",
    "        #Approximate cost\n",
    "        if GPT_MODEL == \"gpt-4\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.03, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.06, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            #final_cost = total_cost_summarise_job + cost_classify\n",
    "            #print(f\"FINAL COST: ${final_cost} USD\")\n",
    "        elif GPT_MODEL == \"gpt-3.5-turbo\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.0015, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.002, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            #final_cost = total_cost_summarise_job + cost_classify\n",
    "            #print(f\"FINAL COST: ${final_cost} USD\")\n",
    "        elif GPT_MODEL == \"gpt-3.5-turbo-16k\":\n",
    "            prompt_cost = round((prompt_tokens / 1000) * 0.003, 3)\n",
    "            completion_cost = round((completion_tokens / 1000) * 0.004, 3)\n",
    "            cost_classify = prompt_cost + completion_cost\n",
    "            print(f\"COST FOR CLASSIFYING:\", f\"${cost_classify} USD\")\n",
    "            #print(f\"COST FOR SUMMARISING:\", f\"${total_cost_summarise_job} USD\")\n",
    "            #final_cost = total_cost_summarise_job + cost_classify\n",
    "            #print(f\"FINAL COST: ${final_cost} USD\")\n",
    "\n",
    "        #relatednesses\n",
    "        ids, relatednesses = ids_ranked_by_relatedness_e5(query=query, df=df)\n",
    "        print(f\"\\nTHE IDs ARE RANKED BY RELEVANCE:\\n\")\n",
    "        for id, relatedness in zip(ids, relatednesses):\n",
    "            print(f\"ID: {id} has the following {relatedness=:.3f}\")\n",
    "        \n",
    "        elapsed_time = timeit.default_timer() - start_time\n",
    "        print(\"\\n\", f\"DreamedJobAI finished! all in: {elapsed_time:.2f} seconds\", \"\\n\") \n",
    "    return response_message\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(ask(abstract_cv))\n",
      "Cell \u001b[0;32mIn[42], line 11\u001b[0m, in \u001b[0;36mask\u001b[0;34m(query, df, model, token_budget, print_gpt_messages, print_cost_and_relatednesses)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask\u001b[39m(\n\u001b[1;32m      2\u001b[0m     \u001b[39m#This query is your question, only parameter to fill in function\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[39m#Answers a query using GPT and a dataframe of relevant texts and embeddings.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     query_user, job_id_description, total_cost_summarise_job \u001b[39m=\u001b[39m query_message(query, df, model\u001b[39m=\u001b[39;49mmodel, token_budget\u001b[39m=\u001b[39;49mtoken_budget)\n\u001b[1;32m     12\u001b[0m     messages \u001b[39m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: system_prompt},\n\u001b[1;32m     14\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdelimiters\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mquery_user\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mdelimiters\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     15\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: job_id_description}\n\u001b[1;32m     16\u001b[0m     ]\n\u001b[1;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m print_gpt_messages:\n",
      "Cell \u001b[0;32mIn[40], line 19\u001b[0m, in \u001b[0;36mquery_message\u001b[0;34m(query, df, model, token_budget)\u001b[0m\n\u001b[1;32m     16\u001b[0m job_description \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mid\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext_data\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \n\u001b[1;32m     18\u001b[0m \u001b[39m#Summarise the job description with GPT-3.5\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m job_summarised, cost \u001b[39m=\u001b[39m summarise_job(job_description)\n\u001b[1;32m     20\u001b[0m total_cost_summarise_job \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cost\n\u001b[1;32m     21\u001b[0m \u001b[39m# Add job descriptions to the message along with job ID\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/utils/SummariseJob.py:27\u001b[0m, in \u001b[0;36msummarise_job\u001b[0;34m(job_to_summarise)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummarise_job\u001b[39m(job_to_summarise):\n\u001b[0;32m---> 27\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     28\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     29\u001b[0m             {\u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m: system_query},\n\u001b[1;32m     30\u001b[0m             {\u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m: job_to_summarise},\n\u001b[1;32m     31\u001b[0m             {\u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39massistant\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m:assistant_query}\n\u001b[1;32m     32\u001b[0m         ],\n\u001b[1;32m     33\u001b[0m         model\u001b[39m=\u001b[39;49mMODEL,\n\u001b[1;32m     34\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     35\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     response_message \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m     total_cost \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FundacionUniversidaddelasAmericasPuebla/DEVELOPER/PROJECTS/DreamedJobAI/e5/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "print(ask(abstract_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_3_summary = \"\"\"Write an abstract description of the following CV in four bullet points. \n",
    "\n",
    "Let's think step by step to summarise it into four bullet points:\n",
    "\n",
    "1. Focus on the main skills and responsibilities of each role. \n",
    "2. One of the bullet points is the total years of experience.\n",
    "2. Omit the employer names. \n",
    "3. Your answer must be in an active voice. \n",
    "4. Double-check that the summary is in four bullet points, three summarising the main skills and responsibilities and the last one is about the years of experience. \n",
    "CV IS BELOW: \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
