2023-06-26 21:55:57,590 INFO: 
error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4229 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False

2023-06-26 22:00:24,267 INFO: 
error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4229 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False

2023-06-26 22:01:22,098 INFO: 
error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4229 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False

